{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Wavenet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "# seed for reproductibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# load the dataset\n",
    "with open(file=\"datasets/names.txt\", mode=\"r\") as namestxt:\n",
    "    words = namestxt.read().splitlines() \n",
    "    \n",
    "# build a dictionary for the characters\n",
    "chars = [\".\"] + sorted(list(set(\"\".join(words))))\n",
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "\n",
    "# shuffle the words\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "\n",
    "# build the dataset\n",
    "block_size = 3 # lengths of sequence of token \n",
    "def build_dataset(words, train=0.8, dev=0.1, test=0.1): # helper function to create datasets\n",
    "\tif train + test + dev != 1:\n",
    "\t\treturn ValueError\n",
    "\t\n",
    "\tX, Y = [], []\n",
    "\tfor word in words:\n",
    "\t\tcontext = [0]*block_size\n",
    "\t\tfor char in word + \".\":\n",
    "\t\t\tix = stoi[char]\n",
    "\t\t\tX.append(context)\n",
    "\t\t\tY.append(ix)\n",
    "\t\t\tcontext = context[1:]+[ix]\n",
    "\tX = torch.tensor(X)\n",
    "\tY = torch.tensor(Y)\n",
    "\n",
    "\tn1 = int(train*(len(words)))\n",
    "\tn2 = int((train + dev)*(len(words)))\n",
    "\n",
    "\tXtr, Ytr = X[:n1], Y[:n1]\n",
    "\tXdev, Ydev = X[n1:n2], Y[n1:n2]\n",
    "\tXtest, Ytest = X[n2:], Y[n2:]\n",
    "\n",
    "\treturn Xtr, Ytr, Xdev, Ydev, Xtest, Ytest\n",
    "\n",
    "Xtr, Ytr, Xdev, Ydev, Xtest, Ytest = build_dataset(words=words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ---> y\n",
      "..y ---> u\n",
      ".yu ---> h\n",
      "yuh ---> e\n",
      "uhe ---> n\n",
      "hen ---> g\n",
      "eng ---> .\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(Xtr[:7], Ytr[:7]):\n",
    "\tprint(\"\".join(itos[ix.item()] for ix in x), \"--->\", itos[y.item()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some Layers Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear: # linear layer\n",
    "\n",
    "\tdef __init__(self, fan_in, fan_out, bias = True):\n",
    "\t\tself.weight = torch.randn((fan_in, fan_out))/(fan_in**0.5)\n",
    "\t\tself.bias = torch.zeros(fan_out) if bias else None\n",
    "\t\n",
    "\tdef __call__(self, x):\n",
    "\t\tself.out = x @ self.weight\n",
    "\t\tif self.bias is not None:\n",
    "\t\t\tself.out += self.bias\n",
    "\t\treturn self.out\n",
    "\n",
    "\tdef parameters(self):\n",
    "\t\treturn [self.weight] + ([] if self.bias == None else [self.bias])\n",
    "\t\n",
    "class Batchnorm1d:\n",
    "\n",
    "\tdef __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "\t\tself.eps = eps\n",
    "\t\tself.momentum = momentum\n",
    "\t\tself.training = True\n",
    "\t\t# parameters trained with backprop\n",
    "\t\tself.gamma = torch.ones(dim)\n",
    "\t\tself.beta = torch.zeros(dim)\n",
    "\t\t# buffer, trained with running mean and var\n",
    "\t\tself.running_mean = torch.zeros(dim)\n",
    "\t\tself.running_var = torch.ones(dim)\n",
    "\n",
    "\tdef __call__(self, x):\n",
    "\t\t# calculate batch mean and var during training, running mean and var for inference\n",
    "\t\tif self.training:\n",
    "\t\t\txmean = x.mean(0, keepdim = True)\n",
    "\t\t\txvar = x.var(0, keepdim = True)\n",
    "\t\t# for inference\n",
    "\t\telse:\n",
    "\t\t\txmean = self.running_mean\n",
    "\t\t\txvar = self.running_var\n",
    "\t\txhat = (x-xmean)/torch.sqrt(xvar + self.eps)\n",
    "\t\tself.out = self.gamma * xhat + self.beta\n",
    "\t\t# if training, update the running mean and variance\n",
    "\t\tif self.training:\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tself.running_mean = self.running_mean * (1-self.momentum) + xmean * self.momentum\n",
    "\t\t\t\tself.running_var = self.running_var * (1-self.momentum) + xvar * self.momentum\n",
    "\t\t\n",
    "\t\treturn self.out\n",
    "\n",
    "\tdef parameters(self):\n",
    "\t\treturn [self.gamma,self.beta]\n",
    "\n",
    "class Tanh:\n",
    "\tdef __call__(self, x):\n",
    "\t\tself.out = torch.tanh(x)\n",
    "\t\treturn self.out\n",
    "\tdef parameters(self):\n",
    "\t\treturn []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the NN = 12097\n"
     ]
    }
   ],
   "source": [
    "n_emb = 10 # dimension of embedding layer\n",
    "n_hidden = 200 # dimension of the hidden layer\n",
    "\n",
    "# layers of the NN\n",
    "C = torch.randn(vocab_size, n_emb) # word embedding\n",
    "layers = [\n",
    "\tLinear(fan_in = (n_emb*block_size), fan_out = n_hidden, bias=False),\n",
    "\tBatchnorm1d(dim = n_hidden),\n",
    "\tTanh(),\n",
    "\tLinear(fan_in= n_hidden, fan_out= vocab_size)\n",
    "]\n",
    "\n",
    "# smooth parameter init last Layer (less confident)\n",
    "with torch.no_grad():\n",
    "\tlayers[-1].weight *= 0.1 \n",
    "\n",
    "# create list of all parameters\n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(f\"Number of parameters in the NN = {sum(p.nelement() for p in parameters)}\")\n",
    "\n",
    "# requires grad\n",
    "for p in parameters:\n",
    "\tp.requires_grad = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3]) torch.Size([32])\n",
      "Loss of step 0 from 1 = 1.758811116218567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2851993f0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_steps = 1 # TODO desactivate\n",
    "# max_steps = 200000 # TODO activate\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "train_size = Xtr.shape[0]\n",
    "\n",
    "for i in range(max_steps):\n",
    "\t# build minibatch\n",
    "\tix = torch.randint(low=0,high=train_size,size=(batch_size,))\n",
    "\tXb, Yb = Xtr[ix], Ytr[ix] \n",
    "\n",
    "\t# forward pass\n",
    "\temb = C[Xb] # embedding the individual tokens \n",
    "\tx = emb.view(batch_size, (block_size*n_emb)) # concatenate the vectors (one row per set of 3 token)\n",
    "\tfor layer in layers:\n",
    "\t\tx = layer(x) # go through the layers of the NN \n",
    "\tloss = F.cross_entropy(input=x, target=Yb) # loss function\n",
    "\tprint(Xb.shape, Yb.shape)\n",
    "\t\n",
    "\t# backward pass\n",
    "\tfor p in parameters:\n",
    "\t\tp.grad = None\n",
    "\tloss.backward()\n",
    "\t\n",
    "\t# update weights (simple Stochastic Gradient Descent)\n",
    "\tfor p in parameters:\n",
    "\t\tlr = 0.1 if i<(max_steps*0.75) else 0.01 #learning rate decay\n",
    "\t\tp.data -= p.grad * lr\n",
    "\t\n",
    "\t# track stats\n",
    "\tlossi.append(loss.log10().item())\n",
    "\tif i%10000 == 0:\n",
    "\t\tprint(f\"Loss of step {i} from {max_steps} = {loss}\")\n",
    "# Plot the result of the training\n",
    "plt.plot(lossi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 1.8166677951812744\n",
      "val loss = 2.340102195739746\n"
     ]
    }
   ],
   "source": [
    "# desactivate the training mode for inference\n",
    "for layer in layers:\n",
    "    layer.training = False\n",
    "    \n",
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    x, y = {\n",
    "        \"train\": (Xtr, Ytr),\n",
    "        \"val\": (Xdev, Ydev),\n",
    "        \"test\": (Xtest, Ytest)\n",
    "\t}[split]\n",
    "    emb = C[x]\n",
    "    x = emb.view(emb.shape[0], -1)\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x, y)\n",
    "    print(f\"{split} loss = {loss}\")\n",
    "\n",
    "split_loss(\"train\")\n",
    "split_loss(\"val\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mo.\n",
      "yntyeaala.\n",
      "aaja.\n",
      "fhldl.\n",
      "bii.\n",
      "h.\n",
      "pfhl.\n",
      "cctll.\n",
      "n.\n",
      "jhl.\n",
      "jvajhlaaa.\n",
      "ribhs.\n",
      "aa.\n",
      "veaaytaaa.\n",
      "qi.\n",
      "jakaaval.\n",
      "o.\n",
      "ve.\n",
      "kdcntela.\n",
      "l.\n"
     ]
    }
   ],
   "source": [
    "# function to sample from the model\n",
    "def sampleNames(sample_size = 20):\n",
    "\tfor _ in range(sample_size):\n",
    "\t\tcontext = [0] * block_size\n",
    "\t\tout = []\n",
    "\t\t# a while loop for each sample\n",
    "\t\twhile True:\n",
    "\t\t\t# forward pass\n",
    "\t\t\temb = torch.Tensor(size=(3,10))\n",
    "\t\t\tfor i in range(len(context)):\n",
    "\t\t\t\temb[i] = C[context[i]]\n",
    "\t\t\tx = emb.view(emb.shape[0]*emb.shape[1])\n",
    "\t\t\tfor layer in layers:\n",
    "\t\t\t\tx = layer(x)\n",
    "\t\t\tprobs = F.softmax(input=x, dim = 1) # probability distribution for each token\n",
    "\t\t\tix = torch.multinomial(input=probs, num_samples=1, replacement=False).item()\n",
    "\t\t\tcontext = [ix] + context[1:]\n",
    "\t\t\tout.append(ix)\n",
    "\t\t\tif ix == 0:\n",
    "\t\t\t\tbreak\n",
    "\t\tprint(\"\".join(itos[i] for i in out))\n",
    "\t\n",
    "sampleNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25626"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
